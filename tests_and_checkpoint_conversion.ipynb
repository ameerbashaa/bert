{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q git+https://github.com/deepmipt/bert.git@feat/keras1 deeppavlov tensorflow==1.14.0rc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0-rc0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/multi_cased_L-12_H-768_A-12.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.get_file(\n",
    "    fname='multi_cased_L-12_H-768_A-12.zip',\n",
    "    # 'rubert_cased_L-12_H-768_A-12_v1.tar.gz',\n",
    "    origin='https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip',\n",
    "    # 'http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz',\n",
    "    cache_subdir='models',\n",
    "    extract=True,\n",
    "    cache_dir='.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants to construct input tensors\n",
    "BATCH_SIZE = 4\n",
    "MAX_LEN = 512\n",
    "\n",
    "input_ids = np.array([[101, 142] + [1, 3, 2, 5] * (MAX_LEN // 4 - 1) + [4242, 102],\n",
    "                      [101] + [1, 2, 3] * (MAX_LEN // 4 - 1) + [142, 102] + [0] * (MAX_LEN // 4)] * (BATCH_SIZE // 2))\n",
    "input_mask = np.int32(np.not_equal(input_ids, 0))\n",
    "\n",
    "transparent_input_mask = np.ones_like(input_ids)\n",
    "\n",
    "sep_ids = np.int32(np.equal(input_ids, 102))\n",
    "\n",
    "token_types = np.cumsum(sep_ids, axis=1) - sep_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactored implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bert_dp import bert\n",
    "keras_graph = tf.compat.v1.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0603 11:39:03.924747 139724026029888 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/bert/bert_dp/embeddings.py:29: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "W0603 11:39:03.925686 139724026029888 deprecation.py:506] From /home/nab/PycharmProjects/work/venv/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0603 11:39:03.934399 139724026029888 deprecation.py:506] From /home/nab/PycharmProjects/work/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "with keras_graph.as_default():\n",
    "    bm_ = bert.BERT(trainable=False, name='bert')\n",
    "    keras_sess = tf.compat.v1.Session()\n",
    "#     inp = tf.keras.layers.Input(shape=(None,), batch_size=BATCH_SIZE, dtype=tf.int32)\n",
    "    out = bm_(input_ids)  # bm_(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'bert/embeddings/word_embeddings:0' shape=(119547, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/pooler/dense/bias:0' shape=(768,) dtype=float32>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_graph.get_collection('trainable_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0603 11:39:11.909543 139724026029888 deprecation.py:323] From /home/nab/PycharmProjects/work/venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "with keras_graph.as_default():\n",
    "    from tensorflow.python.ops import variables\n",
    "    keras_vs = variables._all_saveable_objects()\n",
    "    keras_saver = tf.compat.v1.train.Saver(keras_vs)\n",
    "    keras_sess.run(tf.global_variables_initializer())\n",
    "    keras_saver_checkpoint_path = 'models/multi_cased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "    # 'models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt'\n",
    "    keras_saver.restore(keras_sess, keras_saver_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras_graph.as_default():\n",
    "    # object-based loading/saving... not currently working\n",
    "#     checkpoint_path = 'models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt'\n",
    "#     checkpoint = tf.train.Checkpoint(model=bm_)\n",
    "#     status = checkpoint.restore(checkpoint_path).assert_consumed().initializer_or_restore(session=keras_sess)\n",
    "    # conversion for future usage\n",
    "    bm_.save_weights(# 'models/rubert_converted_checkpoint/bert_model'\n",
    "                     'models/bert_multi_cased_L-12_H-768_A-12_converted/bert_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bert_dp.modeling import BertModel, BertConfig\n",
    "orig_graph = tf.compat.v1.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0603 11:39:28.310317 139724026029888 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/bert/bert_dp/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0603 11:39:28.320179 139724026029888 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/bert/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0603 11:39:28.322921 139724026029888 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/bert/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0603 11:39:28.353576 139724026029888 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/bert/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0603 11:39:28.748600 139724026029888 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0603 11:39:28.782198 139724026029888 deprecation.py:323] From /home/nab/PycharmProjects/work/bert/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0603 11:39:29.027094 139724026029888 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/venv/lib/python3.6/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with orig_graph.as_default():\n",
    "\n",
    "    input_ids_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='ids_ph')\n",
    "    input_masks_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='masks_ph')\n",
    "    token_types_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='token_types_ph')\n",
    "\n",
    "    orig_sess = tf.compat.v1.Session()\n",
    "    bm = BertModel(config=BertConfig.from_json_file('models/rubert_cased_L-12_H-768_A-12_v1/bert_config.json'),\n",
    "                   is_training=False,\n",
    "                   input_ids=input_ids_ph,\n",
    "                   input_mask=input_masks_ph,\n",
    "                   token_type_ids=token_types_ph,\n",
    "                   use_one_hot_embeddings=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'bert/embeddings/word_embeddings:0' shape=(119547, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/pooler/dense/bias:0' shape=(768,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_graph.get_collection('trainable_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with orig_graph.as_default():\n",
    "    from tensorflow.python.ops import variables\n",
    "    orig_vs = variables._all_saveable_objects()\n",
    "    orig_saver = tf.compat.v1.train.Saver(orig_vs)\n",
    "    orig_saver_checkpoint_path = 'models/multi_cased_L-12_H-768_A-12/bert_model.ckpt' # 'models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt'\n",
    "    orig_saver.restore(orig_sess, orig_saver_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'models/multi_cased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "# 'models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt'\n",
    "var_names = tf.train.list_variables(checkpoint_path)\n",
    "checkpoint_reader = tf.train.load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_vars = set()\n",
    "for v, _ in var_names:\n",
    "    checkpoint_vars.add(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert/embeddings/LayerNorm/beta',\n",
       " 'bert/embeddings/LayerNorm/gamma',\n",
       " 'bert/embeddings/position_embeddings',\n",
       " 'bert/embeddings/token_type_embeddings',\n",
       " 'bert/embeddings/word_embeddings',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/output/dense/bias',\n",
       " 'bert/encoder/layer_0/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/output/dense/bias',\n",
       " 'bert/encoder/layer_1/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/output/dense/bias',\n",
       " 'bert/encoder/layer_10/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/output/dense/bias',\n",
       " 'bert/encoder/layer_11/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/output/dense/bias',\n",
       " 'bert/encoder/layer_2/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/output/dense/bias',\n",
       " 'bert/encoder/layer_3/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/output/dense/bias',\n",
       " 'bert/encoder/layer_4/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/output/dense/bias',\n",
       " 'bert/encoder/layer_5/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/output/dense/bias',\n",
       " 'bert/encoder/layer_6/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/output/dense/bias',\n",
       " 'bert/encoder/layer_7/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/output/dense/bias',\n",
       " 'bert/encoder/layer_8/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/output/dense/bias',\n",
       " 'bert/encoder/layer_9/output/dense/kernel',\n",
       " 'bert/pooler/dense/bias',\n",
       " 'bert/pooler/dense/kernel',\n",
       " 'cls/predictions/output_bias',\n",
       " 'cls/predictions/transform/LayerNorm/beta',\n",
       " 'cls/predictions/transform/LayerNorm/gamma',\n",
       " 'cls/predictions/transform/dense/bias',\n",
       " 'cls/predictions/transform/dense/kernel',\n",
       " 'cls/seq_relationship/output_bias',\n",
       " 'cls/seq_relationship/output_weights'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checkpoint_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_model_vars = set()\n",
    "for v in bm_.variables:\n",
    "    bert_model_vars.add(v.name.split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert/embeddings/LayerNorm/beta',\n",
       " 'bert/embeddings/LayerNorm/gamma',\n",
       " 'bert/embeddings/position_embeddings',\n",
       " 'bert/embeddings/token_type_embeddings',\n",
       " 'bert/embeddings/word_embeddings',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/output/dense/bias',\n",
       " 'bert/encoder/layer_0/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/output/dense/bias',\n",
       " 'bert/encoder/layer_1/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/output/dense/bias',\n",
       " 'bert/encoder/layer_10/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/output/dense/bias',\n",
       " 'bert/encoder/layer_11/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/output/dense/bias',\n",
       " 'bert/encoder/layer_2/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/output/dense/bias',\n",
       " 'bert/encoder/layer_3/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/output/dense/bias',\n",
       " 'bert/encoder/layer_4/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/output/dense/bias',\n",
       " 'bert/encoder/layer_5/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/output/dense/bias',\n",
       " 'bert/encoder/layer_6/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/output/dense/bias',\n",
       " 'bert/encoder/layer_7/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/output/dense/bias',\n",
       " 'bert/encoder/layer_8/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/output/dense/bias',\n",
       " 'bert/encoder/layer_9/output/dense/kernel',\n",
       " 'bert/pooler/dense/bias',\n",
       " 'bert/pooler/dense/kernel'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_model_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equality testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bert/embeddings/word_embeddings:0' shape=(119547, 768) dtype=float32>\n",
      "<tf.Variable 'bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>\n",
      "<tf.Variable 'bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>\n",
      "<tf.Variable 'bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>\n",
      "<tf.Variable 'bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>\n",
      "LayerNorm variables orders are different\n",
      "<tf.Variable 'bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>\n",
      "<tf.Variable 'bert/pooler/dense/bias:0' shape=(768,) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(orig_graph.get_collection('trainable_variables'))):\n",
    "    with orig_graph.as_default():\n",
    "        orig_v = orig_sess.run(orig_graph.get_collection('trainable_variables')[i].read_value())\n",
    "    with keras_graph.as_default():\n",
    "        keras_v = keras_sess.run(keras_graph.get_collection('trainable_variables')[i].read_value())\n",
    "    print(keras_graph.get_collection('trainable_variables')[i])\n",
    "    try:\n",
    "        np.testing.assert_allclose(keras_v, orig_v)\n",
    "    except:\n",
    "        print(\"LayerNorm variables orders are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check at least emb_layer_norm weight are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with orig_graph.as_default():\n",
    "    orig_gamma = orig_sess.run(orig_graph.get_collection('trainable_variables')[4].read_value())\n",
    "    orig_beta = orig_sess.run(orig_graph.get_collection('trainable_variables')[3].read_value())\n",
    "with keras_graph.as_default():\n",
    "    keras_gamma = keras_sess.run(keras_graph.get_collection('trainable_variables')[3].read_value())\n",
    "    keras_beta = keras_sess.run(keras_graph.get_collection('trainable_variables')[4].read_value())\n",
    "np.testing.assert_allclose(keras_gamma, orig_gamma)\n",
    "np.testing.assert_allclose(keras_beta, orig_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with orig_graph.as_default():\n",
    "    current_mask = input_mask\n",
    "    emb_output = orig_sess.run(bm.get_embedding_output(), feed_dict={input_ids_ph: input_ids,\n",
    "                                                                     input_masks_ph: current_mask,\n",
    "                                                                     token_types_ph: token_types})\n",
    "    all_encoder_layers = orig_sess.run(bm.get_all_encoder_layers(), feed_dict={input_ids_ph: input_ids,\n",
    "                                                                               input_masks_ph: current_mask,\n",
    "                                                                               token_types_ph: token_types})\n",
    "    pooled_output = orig_sess.run(bm.get_pooled_output(), feed_dict={input_ids_ph: input_ids,\n",
    "                                                                     input_masks_ph: current_mask,\n",
    "                                                                     token_types_ph: token_types})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras_graph.as_default():\n",
    "    \n",
    "    emb_output_op_ = bm_.embedding_dropout(\n",
    "        bm_.embedding_layer_norm(\n",
    "            bm_.emb(input_ids)\n",
    "        ), training=False\n",
    "    )\n",
    "    all_encoder_layers_op_ = [bm_.layers[3].layers[0](emb_output_op_, mask=tf.constant(current_mask))]\n",
    "    for i in range(1, 12):\n",
    "        all_encoder_layers_op_.append(bm_.layers[3].layers[i](all_encoder_layers_op_[i-1], mask=tf.constant(current_mask)))\n",
    "    emb_output_ = keras_sess.run(emb_output_op_)\n",
    "    all_encoder_layers_ = keras_sess.run(all_encoder_layers_op_)\n",
    "    pooled_output_ = keras_sess.run(bm_(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(emb_output_, emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    np.testing.assert_allclose(all_encoder_layers_[i], all_encoder_layers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(pooled_output_, pooled_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraphraser testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.deeppavlov.ai/deeppavlov_data/classifiers/paraphraser_rubert_v0.tar.gz\n",
      "659120128/659112375 [==============================] - 14s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./models/paraphraser_rubert_v0.tar.gz'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.get_file(\n",
    "    fname='paraphraser_rubert_v0.tar.gz',\n",
    "    origin='http://files.deeppavlov.ai/deeppavlov_data/classifiers/paraphraser_rubert_v0.tar.gz',\n",
    "    cache_subdir='models',\n",
    "    extract=True,\n",
    "    cache_dir='.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_dp.modeling import attention_layer, layer_norm, create_attention_mask_from_input_mask, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_dp.modeling import get_shape_list, reshape_from_matrix, reshape_to_matrix, create_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_dp.activations import gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mask = input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with orig_graph.as_default():\n",
    "    msk = orig_sess.run(tf.expand_dims(\n",
    "        create_attention_mask_from_input_mask(tf.constant(emb_output),\n",
    "                                              tf.constant(current_mask)),\n",
    "        axis=[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 512, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras_graph.as_default():\n",
    "    msk_ = keras_sess.run(bm_.create_self_attention_mask_from_input_mask(\n",
    "#         tf.constant(emb_output),\n",
    "        tf.constant(current_mask)\n",
    "    )\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 1, 512)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(msk_, msk[:, :, 1:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.compat.v1.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    reuse = tf.compat.v1.AUTO_REUSE\n",
    "    with tf.compat.v1.variable_scope(\"bert/encoder/layer_0/attention\", reuse=reuse):\n",
    "        with tf.compat.v1.variable_scope(\"self\", reuse=None):\n",
    "#             attention_head = attention_layer(\n",
    "            from_tensor=tf.constant(emb_output)  # ,\n",
    "            to_tensor=tf.constant(emb_output)  # ,\n",
    "            attention_mask=create_attention_mask_from_input_mask(from_tensor=tf.constant(emb_output),\n",
    "                                                                 to_mask=tf.constant(current_mask))  # ,\n",
    "            num_attention_heads=12  # ,\n",
    "            size_per_head=(768 // 12)  # ,\n",
    "            query_act = None,\n",
    "            key_act = None,\n",
    "            value_act = None\n",
    "            attention_probs_dropout_prob=0.0  # , # !\n",
    "            initializer_range=0.02  # ,\n",
    "            do_return_2d_tensor=False  # ,\n",
    "            batch_size=BATCH_SIZE  # ,\n",
    "            from_seq_length=MAX_LEN  # ,\n",
    "            to_seq_length=MAX_LEN\n",
    "#             )\n",
    "            def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n",
    "                           seq_length, width):\n",
    "                output_tensor = tf.reshape(\n",
    "                    input_tensor, [batch_size, seq_length, num_attention_heads, width])\n",
    "\n",
    "                output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n",
    "                return output_tensor\n",
    "\n",
    "            from_shape = get_shape_list(from_tensor, expected_rank=[2, 3], name='from')\n",
    "            to_shape = get_shape_list(to_tensor, expected_rank=[2, 3], name='to')\n",
    "\n",
    "            if len(from_shape) != len(to_shape):\n",
    "                raise ValueError(\"The rank of `from_tensor` must match the rank of `to_tensor`.\")\n",
    "\n",
    "            if len(from_shape) == 3:\n",
    "                batch_size = from_shape[0]\n",
    "                from_seq_length = from_shape[1]\n",
    "                to_seq_length = to_shape[1]\n",
    "            elif len(from_shape) == 2:\n",
    "                if (batch_size is None or from_seq_length is None or to_seq_length is None):\n",
    "                    raise ValueError(\n",
    "                        \"When passing in rank 2 tensors to attention_layer, the values \"\n",
    "                        \"for `batch_size`, `from_seq_length`, and `to_seq_length` \"\n",
    "                        \"must all be specified.\")\n",
    "\n",
    "            # Scalar dimensions referenced here:\n",
    "            #   B = batch size (number of sequences)\n",
    "            #   F = `from_tensor` sequence length\n",
    "            #   T = `to_tensor` sequence length\n",
    "            #   N = `num_attention_heads`\n",
    "            #   H = `size_per_head`\n",
    "\n",
    "            from_tensor_2d = reshape_to_matrix(from_tensor)\n",
    "            to_tensor_2d = reshape_to_matrix(to_tensor)\n",
    "\n",
    "            # `query_layer` = [B*F, N*H]\n",
    "            query_layer_ = tf.layers.dense(\n",
    "              from_tensor_2d,\n",
    "              num_attention_heads * size_per_head,\n",
    "#               activation=query_act,\n",
    "              name=\"query\",\n",
    "              kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "            # `key_layer` = [B*T, N*H]\n",
    "            key_layer_ = tf.layers.dense(\n",
    "              to_tensor_2d,\n",
    "              num_attention_heads * size_per_head,\n",
    "#               activation=key_act,\n",
    "              name=\"key\",\n",
    "              kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "            # `value_layer` = [B*T, N*H]\n",
    "            value_layer_ = tf.layers.dense(\n",
    "              to_tensor_2d,\n",
    "              num_attention_heads * size_per_head,\n",
    "#               activation=value_act,\n",
    "              name=\"value\",\n",
    "              kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "            # `query_layer` = [B, N, F, H]\n",
    "            query_layer = transpose_for_scores(query_layer_, batch_size,\n",
    "                                             num_attention_heads, from_seq_length,\n",
    "                                             size_per_head)\n",
    "\n",
    "            # `key_layer` = [B, N, T, H]\n",
    "            key_layer = transpose_for_scores(key_layer_, batch_size, num_attention_heads,\n",
    "                                           to_seq_length, size_per_head)\n",
    "\n",
    "            # Take the dot product between \"query\" and \"key\" to get the raw\n",
    "            # attention scores.\n",
    "            # `attention_scores` = [B, N, F, T]\n",
    "            raw_attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n",
    "            raw_attention_scores = tf.multiply(raw_attention_scores,\n",
    "                                         1.0 / math.sqrt(float(size_per_head)))\n",
    "\n",
    "            if attention_mask is not None:\n",
    "                # `attention_mask` = [B, 1, F, T]\n",
    "                attention_mask = tf.expand_dims(attention_mask, axis=[1])\n",
    "\n",
    "                # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "                # masked positions, this operation will create a tensor which is 0.0 for\n",
    "                # positions we want to attend and -10000.0 for masked positions.\n",
    "                adder = (1.0 - tf.cast(attention_mask, tf.float32)) * -10000.0\n",
    "\n",
    "                # Since we are adding it to the raw scores before the softmax, this is\n",
    "                # effectively the same as removing these entirely.\n",
    "                attention_scores = raw_attention_scores + adder\n",
    "\n",
    "            # Normalize the attention scores to probabilities.\n",
    "            # `attention_probs` = [B, N, F, T]\n",
    "            attention_probs = tf.nn.softmax(attention_scores)\n",
    "\n",
    "            # This is actually dropping out entire tokens to attend to, which might\n",
    "            # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "#             attention_probs = dropout(attention_probs, attention_probs_dropout_prob)\n",
    "\n",
    "            # `value_layer` = [B, T, N, H]\n",
    "            value_layer = tf.reshape(\n",
    "              value_layer_,\n",
    "              [batch_size, to_seq_length, num_attention_heads, size_per_head])\n",
    "\n",
    "            # `value_layer` = [B, N, T, H]\n",
    "            value_layer = tf.transpose(value_layer, [0, 2, 1, 3])\n",
    "\n",
    "            # `context_layer` = [B, N, F, H]\n",
    "            context_layer_ = tf.matmul(attention_probs, value_layer)\n",
    "\n",
    "            # `context_layer` = [B, F, N, H]\n",
    "            context_layer = tf.transpose(context_layer_, [0, 2, 1, 3])\n",
    "\n",
    "            if do_return_2d_tensor:\n",
    "                # `context_layer` = [B*F, N*H]\n",
    "                attention_head = tf.reshape(\n",
    "                    context_layer,\n",
    "                    [batch_size * from_seq_length, num_attention_heads * size_per_head])\n",
    "            else:\n",
    "                # `context_layer` = [B, F, N*H]\n",
    "                attention_head = tf.reshape(\n",
    "                    context_layer,\n",
    "                    [batch_size, from_seq_length, num_attention_heads * size_per_head])\n",
    "            \n",
    "        with tf.compat.v1.variable_scope(\"output\", reuse=None):\n",
    "            attention_output = tf.layers.dense(\n",
    "                      attention_head,\n",
    "                      768,\n",
    "                      kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "#             attention_output = tf.layers.dropout(attention_output, 0.1)\n",
    "            attention_output = layer_norm(attention_output + tf.constant(emb_output))\n",
    "\n",
    "    # The activation is only applied to the \"intermediate\" hidden layer.\n",
    "    with tf.variable_scope(\"bert/encoder/layer_0/intermediate\", reuse=reuse):\n",
    "        intermediate_output = tf.layers.dense(attention_output,\n",
    "                                              3072,\n",
    "                                              activation=gelu,\n",
    "                                              kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    # Down-project back to `hidden_size` then add the residual.\n",
    "    with tf.variable_scope(\"bert/encoder/layer_0/output\", reuse=reuse):\n",
    "        layer_output = tf.layers.dense(\n",
    "            intermediate_output,\n",
    "            768,\n",
    "            kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "#         layer_output = tf.layers.dropout(layer_output, 0.1)\n",
    "        layer_output = layer_norm(layer_output + attention_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32_ref>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_collection('trainable_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.compat.v1.train.Saver(variables._all_saveable_objects())\n",
    "    saver_checkpoint_path = 'models/multi_cased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "    # 'models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt'\n",
    "    saver.restore(sess, saver_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    q_out = sess.run(query_layer_)\n",
    "    k_out = sess.run(key_layer_)\n",
    "    v_out = sess.run(value_layer_)\n",
    "    qout = sess.run(query_layer)\n",
    "    kout = sess.run(key_layer)\n",
    "    vout = sess.run(value_layer)\n",
    "with keras_graph.as_default():\n",
    "    q_out_ = keras_sess.run(#first_transformer_block.mhsa.split_heads(\n",
    "        first_transformer_block.mhsa.wq(emb_output),\n",
    "#         batch_size=BATCH_SIZE\n",
    "#     )\n",
    "                          )\n",
    "    k_out_ = keras_sess.run(#first_transformer_block.mhsa.split_heads(\n",
    "        first_transformer_block.mhsa.wk(emb_output),\n",
    "#         batch_size=BATCH_SIZE\n",
    "#     )\n",
    "                          )\n",
    "    v_out_ = keras_sess.run(#first_transformer_block.mhsa.split_heads(\n",
    "        first_transformer_block.mhsa.wv(emb_output),\n",
    "#         batch_size=BATCH_SIZE\n",
    "#     )\n",
    "                          )\n",
    "    qout_ = keras_sess.run(first_transformer_block.mhsa.split_heads(\n",
    "        first_transformer_block.mhsa.wq(emb_output),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "                          )\n",
    "    kout_ = keras_sess.run(first_transformer_block.mhsa.split_heads(\n",
    "        first_transformer_block.mhsa.wk(emb_output),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "                          )\n",
    "    vout_ = keras_sess.run(first_transformer_block.mhsa.split_heads(\n",
    "        first_transformer_block.mhsa.wv(emb_output),\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(q_out_.reshape(-1, 768), q_out)\n",
    "np.testing.assert_allclose(k_out_.reshape(-1, 768), k_out)\n",
    "np.testing.assert_allclose(v_out_.reshape(-1, 768), v_out)\n",
    "np.testing.assert_allclose(qout_, qout)\n",
    "np.testing.assert_allclose(kout_, kout)\n",
    "np.testing.assert_allclose(vout_, vout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_dp.attention import scaled_dot_product_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    raw_a_scores = sess.run(raw_attention_scores)\n",
    "    a_scores = sess.run(attention_scores)\n",
    "    a_probs = sess.run(attention_probs)\n",
    "    a_out = sess.run(context_layer_)\n",
    "with keras_graph.as_default():\n",
    "    raw_attention_scores_ = tf.matmul(qout_, kout_, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    raw_attention_scores_ = raw_attention_scores_ / tf.math.sqrt(64.0)\n",
    "    raw_a_scores_ = keras_sess.run(raw_attention_scores_)\n",
    "    attention_mask_ = bm_.create_self_attention_mask_from_input_mask(current_mask)\n",
    "    a_scores_ = keras_sess.run(raw_attention_scores_ + ((1.0 - attention_mask_) * -10000.0))\n",
    "    a_probs_ = keras_sess.run(tf.nn.softmax(a_scores_))  # (..., seq_len_q, seq_len_k)\n",
    "    a_out_ = keras_sess.run(tf.matmul(a_probs_, vout_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(raw_a_scores_, raw_a_scores)\n",
    "np.testing.assert_allclose(a_scores_, a_scores)\n",
    "np.testing.assert_allclose(a_probs_, a_probs, atol=1e-6)\n",
    "np.testing.assert_allclose(a_out_, a_out, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    mhsa = sess.run(attention_head)\n",
    "    attention_output_res = sess.run(attention_output)\n",
    "    intermediate_output_res = sess.run(intermediate_output)\n",
    "    layer_output_res = sess.run(layer_output)\n",
    "with keras_graph.as_default():\n",
    "    mhsa_ = keras_sess.run(first_transformer_block.mhsa(emb_output, emb_output, emb_output,\n",
    "                                                        mask=bm_.create_self_attention_mask_from_input_mask(current_mask)\n",
    "                                                       )\n",
    "                          )\n",
    "\n",
    "    attention_output_ = first_transformer_block.layernorm1(\n",
    "        emb_output + first_transformer_block.dropout1(\n",
    "            first_transformer_block.dense(mhsa), training=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    attention_output_res_ = keras_sess.run(attention_output_)\n",
    "\n",
    "    intermediate_output_res_ = keras_sess.run(first_transformer_block.pff1(attention_output_res_))\n",
    "    \n",
    "    layer_output_ = first_transformer_block.layernorm2(\n",
    "        attention_output_res_ + first_transformer_block.dropout2(\n",
    "            first_transformer_block.pff2(intermediate_output_res_), training=False\n",
    "        )\n",
    "    )\n",
    "    layer_output_res_ = keras_sess.run(layer_output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(mhsa_, mhsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(attention_output_res_, attention_output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(intermediate_output_res_, intermediate_output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(layer_output_res_, layer_output_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
