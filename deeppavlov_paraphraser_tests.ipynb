{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.dataset_readers.paraphraser_reader import ParaphraserReader\n",
    "ds = ParaphraserReader().read(data_path='dataset', do_lower_case=False)\n",
    "texts_a = []\n",
    "texts_b = []\n",
    "labels = []\n",
    "for (ta, tb), label in ds['test']:\n",
    "    texts_a.append(ta)\n",
    "    texts_b.append(tb)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 18:09:15.905 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/paraphraser_rubert_v0.tar.gz download because of matching hashes\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0617 18:09:15.905855 140398082541376 download.py:116] Skipped http://files.deeppavlov.ai/deeppavlov_data/classifiers/paraphraser_rubert_v0.tar.gz download because of matching hashes\n",
      "2019-06-17 18:09:16.824 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
      "I0617 18:09:16.824452 140398082541376 download.py:116] Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz download because of matching hashes\n",
      "2019-06-17 18:09:16.840 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/datasets/paraphraser.zip download because of matching hashes\n",
      "I0617 18:09:16.840891 140398082541376 download.py:116] Skipped http://files.deeppavlov.ai/datasets/paraphraser.zip download because of matching hashes\n",
      "2019-06-17 18:09:16.847 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/datasets/paraphraser_gold.zip download because of matching hashes\n",
      "I0617 18:09:16.847515 140398082541376 download.py:116] Skipped http://files.deeppavlov.ai/datasets/paraphraser_gold.zip download because of matching hashes\n",
      "[nltk_data] Downloading package punkt to /home/nab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/nab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to /home/nab/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/nab/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "W0617 18:09:18.884157 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/core/models/tf_model.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0617 18:09:18.885343 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/core/models/tf_model.py:223: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0617 18:09:18.885772 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/core/models/tf_model.py:223: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Using TensorFlow backend.\n",
      "W0617 18:09:18.918744 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/core/models/tf_model.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0617 18:09:18.924377 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/bert/bert_dp/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0617 18:09:18.925052 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/models/bert/bert_classifier.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0617 18:09:19.069013 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/models/bert/bert_classifier.py:155: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0617 18:09:19.074146 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/bert/bert_dp/embeddings.py:49: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "W0617 18:09:19.074666 140398082541376 deprecation.py:506] From /home/nab/PycharmProjects/work/venv/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0617 18:09:19.079941 140398082541376 deprecation.py:506] From /home/nab/PycharmProjects/work/venv/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0617 18:09:22.262321 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/models/bert/bert_classifier.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0617 18:09:22.269928 140398082541376 deprecation.py:506] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/models/bert/bert_classifier.py:125: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0617 18:09:31.974213 140398082541376 deprecation.py:323] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/models/bert/bert_classifier.py:97: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2019-06-17 18:09:31.976 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /home/nab/.deeppavlov/models/paraphraser_rubert/model_rubert]\n",
      "I0617 18:09:31.976210 140398082541376 tf_model.py:52] [loading model from /home/nab/.deeppavlov/models/paraphraser_rubert/model_rubert]\n",
      "W0617 18:09:31.977716 140398082541376 deprecation_wrapper.py:119] From /home/nab/PycharmProjects/work/DeepPavlov/deeppavlov/core/models/tf_model.py:55: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "\n",
    "para_model = build_model(configs.classifiers.paraphraser_rubert, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = para_model.pipe[-1][-1].graph\n",
    "bert_preprocessor = para_model[0]\n",
    "bert_classifier = para_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = bert_preprocessor(texts_a, texts_b)\n",
    "input_ids = np.array([f.input_ids for f in features_array])\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_dp import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_graph = tf.compat.v1.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_layer(x):\n",
    "    with tf.compat.v1.variable_scope('', reuse=tf.AUTO_REUSE):\n",
    "        output_weights_ = tf.get_variable(\"output_weights\",\n",
    "                                          [2, 768],\n",
    "                                          dtype=tf.float32,\n",
    "                                          initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        output_bias_ = tf.get_variable(\"output_bias\",\n",
    "                                       [2],\n",
    "                                       dtype=tf.float32,\n",
    "                                       initializer=tf.zeros_initializer())\n",
    "    logits_ = tf.matmul(x, output_weights_, transpose_b=True)\n",
    "    logits_ = tf.nn.bias_add(logits_, output_bias_)\n",
    "\n",
    "#     one_hot_labels_ = tf.one_hot(y_ph, depth=2, dtype=tf.float32)\n",
    "\n",
    "#     y_predictions_ = tf.argmax(logits_, axis=-1)\n",
    "#     log_probs_ = tf.nn.log_softmax(logits_, axis=-1)\n",
    "    y_probas_ = tf.nn.softmax(logits_, axis=-1)\n",
    "#     per_example_loss_ = -tf.reduce_sum(one_hot_labels_ * log_probs_, axis=-1)\n",
    "#     loss_ = tf.reduce_mean(per_example_loss_)\n",
    "    return y_probas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras_graph.as_default():\n",
    "    keras_sess = tf.compat.v1.Session()\n",
    "    bm_ = tf.keras.Sequential([bert.BERT(), tf.keras.layers.Lambda(lambda_layer)], name='bert')\n",
    "    bm_.build(input_shape=(BATCH_SIZE, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'bert/embeddings/word_embeddings:0' shape=(119547, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>,\n",
       " <tf.Variable 'bert/pooler/dense/bias:0' shape=(768,) dtype=float32>,\n",
       " <tf.Variable 'output_weights:0' shape=(2, 768) dtype=float32_ref>,\n",
       " <tf.Variable 'output_bias:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_graph.get_collection('trainable_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras_graph.as_default():\n",
    "    from tensorflow.python.ops import variables\n",
    "    keras_vs = variables._all_saveable_objects()\n",
    "    keras_saver = tf.compat.v1.train.Saver(keras_vs)\n",
    "    #     keras_sess.run(tf.global_variables_initializer())\n",
    "    keras_saver_checkpoint_path = 'models/paraphraser_rubert/model_rubert'\n",
    "    keras_saver.restore(keras_sess, keras_saver_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para_model(['9 мая метрополитен Петербурга будет работать круглосуточно'], ['Петербургское метро в ночь на 10 мая будет работать круглосуточно'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "\n",
    "class F1Score(Metric):\n",
    "    \"\"\"Calculates F1 micro, macro or weighted based on the user's choice.\n",
    "    F1 score is the weighted average of precision and\n",
    "    recall. Output range is [0, 1]. This works for both\n",
    "    multi-class and multi-label classification.\n",
    "    Args:\n",
    "       num_classes : Number of unique classes in the dataset.\n",
    "       average : Type of averaging to be performed on data.\n",
    "                 Acceptable values are None, micro, macro and\n",
    "                 weighted.\n",
    "                 Default value is None.\n",
    "    Returns:\n",
    "       F1 score: float\n",
    "    Raises:\n",
    "       ValueError: If the `average` has values other than\n",
    "       [None, micro, macro. weighted].\n",
    "    `average` parameter behavior:\n",
    "    1. If `None` is specified as an input, scores for each\n",
    "       class are returned.\n",
    "    2. If `micro` is specified, metrics like true positivies,\n",
    "       false positives and false negatives are computed\n",
    "       globally.\n",
    "    3. If `macro` is specified, metrics like true positivies,\n",
    "       false positives and false negatives are computed for\n",
    "       each class and their unweighted mean is returned.\n",
    "       Imbalance in dataset is not taken into account for\n",
    "       calculating the score\n",
    "    4. If `weighted` is specified, metrics are computed for\n",
    "       each class and returns the mean weighted by the\n",
    "       number of true instances in each class taking data\n",
    "       imbalance into account.\n",
    "    Usage:\n",
    "    ```python\n",
    "    actuals = tf.constant([[1, 1, 0],[1, 0, 0]],\n",
    "              dtype=tf.int32)\n",
    "    preds = tf.constant([[1, 0, 0],[1, 0, 1]],\n",
    "            dtype=tf.int32)\n",
    "    output = tf.keras.metrics.F1Score(num_classes=3,\n",
    "              average='micro')\n",
    "    output.update_state(actuals, predictions)\n",
    "    print('F1 Micro score is: ',\n",
    "            output.result().numpy()) # 0.6666667\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 average=None,\n",
    "                 name='f1_score',\n",
    "                 dtype=tf.float32):\n",
    "        super(F1Score, self).__init__(name=name)\n",
    "        self.num_classes = num_classes\n",
    "        if average not in (None, 'micro', 'macro', 'weighted'):\n",
    "            raise ValueError(\"Unknown average type. Acceptable values \"\n",
    "                             \"are: [micro, macro, weighted]\")\n",
    "        else:\n",
    "            self.average = average\n",
    "            if self.average == 'micro':\n",
    "                self.axis = None\n",
    "            else:\n",
    "                self.axis = 0\n",
    "        if self.average == 'micro':\n",
    "            self.true_positives = self.add_weight(\n",
    "                'true_positives',\n",
    "                shape=[],\n",
    "                initializer='zeros',\n",
    "                dtype=tf.float32)\n",
    "            self.false_positives = self.add_weight(\n",
    "                'false_positives',\n",
    "                shape=[],\n",
    "                initializer='zeros',\n",
    "                dtype=tf.float32)\n",
    "            self.false_negatives = self.add_weight(\n",
    "                'false_negatives',\n",
    "                shape=[],\n",
    "                initializer='zeros',\n",
    "                dtype=tf.float32)\n",
    "        else:\n",
    "            self.true_positives = self.add_weight(\n",
    "                'true_positives',\n",
    "                shape=[self.num_classes],\n",
    "                initializer='zeros',\n",
    "                dtype=tf.float32)\n",
    "            self.false_positives = self.add_weight(\n",
    "                'false_positives',\n",
    "                shape=[self.num_classes],\n",
    "                initializer='zeros',\n",
    "                dtype=tf.float32)\n",
    "            self.false_negatives = self.add_weight(\n",
    "                'false_negatives',\n",
    "                shape=[self.num_classes],\n",
    "                initializer='zeros',\n",
    "                dtype=tf.float32)\n",
    "            self.weights_intermediate = self.add_weight(\n",
    "                'weights',\n",
    "                shape=[self.num_classes],\n",
    "                initializer='zeros',\n",
    "                dtype=tf.float32)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "\n",
    "        # true positive\n",
    "        self.true_positives.assign_add(\n",
    "            tf.cast(\n",
    "                tf.math.count_nonzero(y_pred * y_true, axis=self.axis),\n",
    "                tf.float32))\n",
    "        # false positive\n",
    "        self.false_positives.assign_add(\n",
    "            tf.cast(\n",
    "                tf.math.count_nonzero(y_pred * (y_true - 1), axis=self.axis),\n",
    "                tf.float32))\n",
    "        # false negative\n",
    "        self.false_negatives.assign_add(\n",
    "            tf.cast(\n",
    "                tf.math.count_nonzero((y_pred - 1) * y_true, axis=self.axis),\n",
    "                tf.float32))\n",
    "        if self.average == 'weighted':\n",
    "            # variable to hold intermediate weights\n",
    "            self.weights_intermediate.assign_add(\n",
    "                tf.cast(tf.reduce_sum(y_true, axis=self.axis), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        p_sum = tf.cast(self.true_positives + self.false_positives, tf.float32)\n",
    "        # calculate precision\n",
    "        precision = tf.math.divide_no_nan(self.true_positives, p_sum)\n",
    "\n",
    "        r_sum = tf.cast(self.true_positives + self.false_negatives, tf.float32)\n",
    "        # calculate recall\n",
    "        recall = tf.math.divide_no_nan(self.true_positives, r_sum)\n",
    "\n",
    "        mul_value = 2 * precision * recall\n",
    "        add_value = precision + recall\n",
    "        f1_int = tf.math.divide_no_nan(mul_value, add_value)\n",
    "        # f1 score\n",
    "        if self.average is not None:\n",
    "            f1_score = tf.reduce_mean(f1_int)\n",
    "        else:\n",
    "            f1_score = f1_int\n",
    "        # condition for weighted f1 score\n",
    "        if self.average == 'weighted':\n",
    "            f1_int_weights = tf.math.divide_no_nan(\n",
    "                self.weights_intermediate,\n",
    "                tf.reduce_sum(self.weights_intermediate))\n",
    "            # weighted f1 score calculation\n",
    "            f1_score = tf.reduce_sum(f1_int * f1_int_weights)\n",
    "\n",
    "        return f1_score\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Returns the serializable config of the metric.\"\"\"\n",
    "\n",
    "        config = {\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"average\": self.average,\n",
    "        }\n",
    "        base_config = super(F1Score, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        # reset state of the variables to zero\n",
    "        if self.average == 'micro':\n",
    "            self.true_positives.assign(0)\n",
    "            self.false_positives.assign(0)\n",
    "            self.false_negatives.assign(0)\n",
    "        else:\n",
    "            self.true_positives.assign(np.zeros(self.num_classes), np.float32)\n",
    "            self.false_positives.assign(np.zeros(self.num_classes), np.float32)\n",
    "            self.false_negatives.assign(np.zeros(self.num_classes), np.float32)\n",
    "            self.weights_intermediate.assign(\n",
    "                np.zeros(self.num_classes), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras_graph.as_default():\n",
    "#     NUM_EPOCHS = 5\n",
    "    # VAL_EVERY_N_BATCHES = 52  # ~50, but better suited for paraphraser dataset\n",
    "    # TRAIN_STEPS_PER_EPOCH = NUM_TRAIN_SAMPLES // BATCH_SIZE\n",
    "    # VALIDATION_STEPS = 512 // BATCH_SIZE  # calculated by hand for now (~546 samples with droppping remainder)\n",
    "    LEARNING_RATE = 2e-05\n",
    "    # learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(initial_learning_rate=LEARNING_RATE,\n",
    "    #                                                               # n. of batches per epoch * ~NUM_EPOCHS for convergence \n",
    "    #                                                               decay_steps=TRAIN_STEPS_PER_EPOCH * NUM_EPOCHS,\n",
    "    #                                                               end_learning_rate=1e-06)\n",
    "    # from bert_dp.weight_decay_optimizers import AdamW\n",
    "    bm_.compile(#optimizer=AdamW(weight_decay=0.01,\n",
    "    #                                             learning_rate=LEARNING_RATE,\n",
    "    #                                             epsilon=1e-6),  # as in bert_dp\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE,\n",
    "                                                   epsilon=1e-6),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "                         F1Score(num_classes=2, average='macro')\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1899/1899 [==============================] - 5s 2ms/sample - loss: 0.6811 - sparse_categorical_accuracy: 0.5951 - f1_score: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "with keras_graph.as_default():\n",
    "    p_ = bm_.predict_classes(input_ids)\n",
    "    bm_.evaluate(x=input_ids, y=labels, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bert_classifier(features_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(p == p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
